#![feature(allocator_api)]
#![feature(error_generic_member_access)]
#![no_std]
#![no_main]

use alloc::{
    borrow::ToOwned as _, boxed::Box, collections::vec_deque::VecDeque, format, sync::Arc,
};
use core::{
    convert::Infallible,
    ffi::c_void,
    hint, ptr,
    sync::atomic::{AtomicBool, Ordering},
    time::Duration,
};

use devtree::Devicetree;
use snafu::ResultExt as _;
use spin::Once;

use self::{
    cpu::Cpuid,
    error::GenericError,
    interrupt::timer::{self, Instant},
    memory::{kernel_space::KernelStack, layout::HeapLayout},
    sync::spinlock::{SpinMutex, SpinMutexCondVar},
    task::{TaskId, scheduler},
};

extern crate alloc;

#[macro_use]
mod console;
#[macro_use]
mod log;
#[macro_use]
mod cpu_local;

mod boot;
mod cpu;
mod drivers;
mod error;
mod interrupt;
mod iter;
mod memory;
mod sync;
mod task;

const ONIX_VERSION: &str = env!("CARGO_PKG_VERSION");
// Generated by https://www.asciiart.eu/text-to-ascii-art
// with Font = Big
const ONIX_LOGO: &str = r"
  ____        _
 / __ \      (_)
| |  | |_ __  ___  __
| |  | | '_ \| \ \/ /
| |__| | | | | |>  <
 \____/|_| |_|_/_/\_\
";

static DEVICETREE: Once<Box<Devicetree>> = Once::new();

fn primary_cpu_entry(cpuid: Cpuid, dtb_pa: usize) -> Result<KernelStack, GenericError> {
    memory::allocator::init();

    println!();
    println!();
    println!("Onix v{ONIX_VERSION}");
    println!("{ONIX_LOGO}");

    let dt = DEVICETREE.try_call_once(|| {
        let dt = unsafe { Devicetree::from_ptr(ptr::with_exposed_provenance(dtb_pa)) }
            .with_whatever_context(|_| {
                format!("failed to parse devicetree at physical address {dtb_pa:#x}")
            })?;
        Ok(dt.to_owned())
    })?;

    let heap_layout =
        HeapLayout::new(dt).whatever_context("failed to compute heap layout from devicetree")?;
    unsafe {
        memory::allocator::add_heap_ranges(heap_layout.heap_ranges());
    }

    cpu::init(dt).whatever_context("failed to initialize CPU table")?;
    cpu_local::init();
    cpu_local::apply(cpuid);
    cpu::set_current_cpuid(cpuid);
    interrupt::init(cpuid);
    memory::kernel_space::init().whatever_context("failed to initialize kernel space")?;
    memory::layout::update_kernel_page_table(&heap_layout)
        .whatever_context("failed to update kernel page table")?;
    memory::kernel_space::apply();

    let stack = memory::kernel_space::allocate_kernel_stack()
        .with_whatever_context(|_| format!("failed to allocate kernel stack for CPU#{cpuid}"))?;

    Ok(stack)
}

fn secondary_cpu_entry(cpuid: Cpuid) -> Result<KernelStack, GenericError> {
    cpu_local::apply(cpuid);
    cpu::set_current_cpuid(cpuid);
    memory::kernel_space::apply();

    let stack = memory::kernel_space::allocate_kernel_stack()
        .with_whatever_context(|_| format!("failed to allocate kernel stack for CPU#{cpuid}"))?;

    Ok(stack)
}

fn main(is_primary: bool) -> Result<Infallible, GenericError> {
    static INIT_COMPLETED: AtomicBool = AtomicBool::new(false);

    if is_primary {
        unsafe {
            start_secondary_cpus();
        }

        let dt = DEVICETREE.get().unwrap();
        drivers::irq::plic::init(dt)
            .whatever_context("failed to initialize PLIC device drivers")?;
        drivers::serial::init(dt).whatever_context("failed to initialize serial device drivers")?;

        INIT_COMPLETED.store(true, Ordering::Release);
    } else {
        while !INIT_COMPLETED.load(Ordering::Acquire) {
            hint::spin_loop();
        }
    }

    drivers::serial::apply();
    interrupt::trap::apply();
    interrupt::timer::start();

    info!("CPU initialized");

    if is_primary {
        spawn_test_tasks();
        spawn_console_task();
    }

    task::scheduler::start()
}

unsafe fn start_secondary_cpus() {
    for cpu in cpu::get_all() {
        if cpu.is_current() {
            continue;
        }
        unsafe {
            boot::start_secondary_cpu(cpu.id());
        }
    }

    // reuse boot stack as heap
    unsafe {
        memory::allocator::add_heap_ranges([memory::layout::kernel_boot_stack_range()]);
    }
}

struct TaskState {
    queue: SpinMutex<VecDeque<(TaskId, u64, Instant)>>,
    message_sent: SpinMutexCondVar,
    message_received: SpinMutexCondVar,
}

fn spawn_console_task() {
    task::spawn(console_task, ptr::null_mut()).unwrap();
}

extern "C" fn console_task(_arg: *mut c_void) -> ! {
    // TODO: retrieve serial path from devicetree
    let serial = drivers::serial::find_serial_by_dtree_path("/soc/serial@10000000").unwrap();
    loop {
        let mut bytes = [0; 64];
        let nread = serial.read(&mut bytes);
        if nread > 0 {
            // echo back
            let mut nwritten = 0;
            while nwritten < nread {
                nwritten += serial.write(&bytes[..nread][nwritten..]);
            }
        }
    }
}

fn spawn_test_tasks() {
    let state = Arc::new(TaskState {
        queue: SpinMutex::new(VecDeque::new()),
        message_sent: SpinMutexCondVar::new(),
        message_received: SpinMutexCondVar::new(),
    });

    task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
}

extern "C" fn tx_task(arg: *mut c_void) -> ! {
    let task_id = scheduler::current_task().id();

    let state: Arc<TaskState> = unsafe { Arc::from_raw(arg.cast()) };

    let mut i = 0;
    let mut queue = state.queue.lock();
    loop {
        if queue.len() < 4 {
            queue.push_back((task_id, i, Instant::now()));
            state.message_sent.notify_one();
            queue.unlock();
            i += 1;
            timer::sleep(Duration::from_millis(50));
            queue = state.queue.lock();
        } else {
            queue = state.message_received.wait(queue);
        }
    }
}

extern "C" fn rx_task(arg: *mut c_void) -> ! {
    let state: Arc<TaskState> = unsafe { Arc::from_raw(arg.cast()) };
    let task = scheduler::current_task();

    let mut handled = 0;
    let mut total_dur = Duration::ZERO;
    let mut min_dur = Duration::MAX;
    let mut max_dur = Duration::ZERO;
    let mut queue = state.queue.lock();
    loop {
        if let Some((_task_id, i, time)) = queue.pop_front() {
            state.message_received.notify_all();
            queue.unlock();
            let dur = time.elapsed();
            min_dur = min_dur.min(dur);
            max_dur = max_dur.max(dur);
            total_dur += dur;
            handled += 1;
            let avg_dur = total_dur / handled;
            if (i + 1) % 50 == 0 {
                info!(
                    "received, handled={handled}, avg_dur={avg_dur:?}, min_dur={min_dur:?}, \
                     max_dur={max_dur:?}"
                );
            }
            let mut shared = task.shared.lock();
            scheduler::yield_execution(&mut shared);
            shared.unlock();
            queue = state.queue.lock();
        } else {
            queue = state.message_sent.wait(queue);
        }
    }
}
