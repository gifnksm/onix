#![feature(allocator_api)]
#![no_std]
#![no_main]

use alloc::{collections::vec_deque::VecDeque, sync::Arc};
use core::{
    ffi::c_void,
    hint,
    sync::atomic::{AtomicBool, Ordering},
    time::Duration,
};

use devicetree::parsed::Devicetree;
use spin::Once;

use self::{
    cpu::Cpuid,
    interrupt::timer,
    memory::layout::MemoryLayout,
    sync::spinlock::{SpinMutex, SpinMutexCondVar},
    task::{TaskId, scheduler},
};

extern crate alloc;

#[macro_use]
mod console;
#[macro_use]
mod log;

mod boot;
mod cpu;
mod interrupt;
mod memory;
mod sync;
mod task;

const ONIX_VERSION: &str = env!("CARGO_PKG_VERSION");
// Generated by https://www.asciiart.eu/text-to-ascii-art
// with Font = Big
const ONIX_LOGO: &str = r"
  ____        _
 / __ \      (_)
| |  | |_ __  ___  __
| |  | | '_ \| \ \/ /
| |__| | | | | |>  <
 \____/|_| |_|_/_/\_\
";

static PRIMARY_CPUID: Once<Cpuid> = Once::new();
static DEVICETREE: Once<Devicetree> = Once::new();

fn primary_cpu_entry(cpuid: Cpuid, dtb_pa: usize) -> *mut u8 {
    PRIMARY_CPUID.call_once(|| cpuid);

    println!();
    println!();
    println!("Onix v{ONIX_VERSION}");
    println!("{ONIX_LOGO}");

    let memory_layout = init_memory(dtb_pa);
    let dtree = DEVICETREE.get().unwrap();
    cpu::init(dtree).unwrap();
    cpu::set_current_cpuid(cpuid);
    interrupt::init(cpuid);
    memory::kernel_space::init(&memory_layout).unwrap();
    memory::kernel_space::apply();

    let stack = memory::kernel_space::allocate_kernel_stack().unwrap();
    let stack_top = stack.top();
    core::mem::forget(stack);
    stack_top as *mut u8
}

fn secondary_cpu_entry(cpuid: Cpuid) -> *mut u8 {
    cpu::set_current_cpuid(cpuid);
    memory::kernel_space::apply();

    let stack = memory::kernel_space::allocate_kernel_stack().unwrap();
    let stack_top = stack.top();
    core::mem::forget(stack);
    stack_top as *mut u8
}

fn main() -> ! {
    static INIT_COMPLETED: AtomicBool = AtomicBool::new(false);

    let primary_cpuid = PRIMARY_CPUID.get().unwrap();
    let is_primary = *primary_cpuid == cpu::current().id();

    if is_primary {
        unsafe {
            start_secondary_cpus();
        }
        task::scheduler::init();
        INIT_COMPLETED.store(true, Ordering::Release);
    } else {
        while !INIT_COMPLETED.load(Ordering::Acquire) {
            hint::spin_loop();
        }
    }

    interrupt::trap::apply();
    interrupt::timer::start();

    info!("CPU initialized");

    if is_primary {
        let state = Arc::new(TaskState {
            queue: SpinMutex::new(VecDeque::new()),
            message_sent: SpinMutexCondVar::new(),
            message_received: SpinMutexCondVar::new(),
        });

        task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
        task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
        task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
        task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
        task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
        task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
        task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
        task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    }

    task::scheduler::start();
}

fn init_memory(dtb_pa: usize) -> MemoryLayout {
    let dtb = unsafe { devicetree::flattened::Devicetree::from_addr(dtb_pa) }.unwrap();
    let memory_layout = MemoryLayout::new(&dtb).unwrap();

    // initialize heap
    unsafe {
        memory::allocator::add_heap_ranges(memory_layout.initial_heap_ranges());
    }

    // parse devicetree blob
    DEVICETREE.call_once(|| dtb.parse().unwrap());

    // reuse devicetree blob range as heap
    unsafe {
        memory::allocator::add_heap_ranges([memory_layout.dtb_range()]);
    }

    memory_layout
}

unsafe fn start_secondary_cpus() {
    for cpu in cpu::get_all() {
        if cpu.is_current() {
            continue;
        }
        unsafe {
            boot::start_secondary_cpu(cpu.id());
        }
    }

    // reuse boot stack as heap
    unsafe {
        memory::allocator::add_heap_ranges([memory::layout::kernel_boot_stack_range()]);
    }
}

struct TaskState {
    queue: SpinMutex<VecDeque<(TaskId, u64)>>,
    message_sent: SpinMutexCondVar,
    message_received: SpinMutexCondVar,
}

extern "C" fn tx_task(arg: *mut c_void) -> ! {
    let task_id = scheduler::current_task().id();

    let state: Arc<TaskState> = unsafe { Arc::from_raw(arg.cast()) };

    let mut i = 0;
    let mut queue = state.queue.lock();
    loop {
        if queue.len() < 4 {
            queue.push_back((task_id, i));
            state.message_sent.notify_one();
            queue.unlock();
            info!("send ({task_id}, {i})");
            i += 1;
            interrupt::wait();
            queue = state.queue.lock();
        } else {
            info!("send waiting...");
            queue = state.message_received.wait(queue);
        }
    }
}

extern "C" fn rx_task(arg: *mut c_void) -> ! {
    let state: Arc<TaskState> = unsafe { Arc::from_raw(arg.cast()) };
    let task = scheduler::current_task();

    let mut queue = state.queue.lock();
    loop {
        if let Some((task_id, i)) = queue.pop_front() {
            state.message_received.notify_all();
            queue.unlock();
            info!("receive ({task_id}, {i})");
            let mut shared = task.shared.lock();
            scheduler::yield_execution(&mut shared);
            shared.unlock();
            queue = state.queue.lock();
        } else {
            info!("receive waiting...");
            queue = state.message_sent.wait(queue);
        }
    }
}
