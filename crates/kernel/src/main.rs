#![feature(allocator_api)]
#![feature(error_generic_member_access)]
#![no_std]
#![no_main]

use alloc::{boxed::Box, collections::vec_deque::VecDeque, sync::Arc};
use core::{
    error,
    ffi::c_void,
    hint,
    sync::atomic::{AtomicBool, Ordering},
    time::Duration,
};

use ansi_term::{Color, WithFg};
use devicetree::parsed::Devicetree;
use snafu::{ResultExt as _, Snafu};
use snafu_utils::{Location, Report};
use spin::Once;

use self::{
    cpu::Cpuid,
    interrupt::timer::{self, Instant},
    main_error::{InitPlicDriversSnafu, InitSerialDriversSnafu},
    memory::layout::MemoryLayout,
    sync::spinlock::{SpinMutex, SpinMutexCondVar},
    task::{TaskId, scheduler},
};

extern crate alloc;

#[macro_use]
mod console;
#[macro_use]
mod log;
#[macro_use]
mod cpu_local;

mod boot;
mod cpu;
mod drivers;
mod interrupt;
mod memory;
mod sync;
mod task;

const ONIX_VERSION: &str = env!("CARGO_PKG_VERSION");
// Generated by https://www.asciiart.eu/text-to-ascii-art
// with Font = Big
const ONIX_LOGO: &str = r"
  ____        _
 / __ \      (_)
| |  | |_ __  ___  __
| |  | | '_ \| \ \/ /
| |__| | | | | |>  <
 \____/|_| |_|_/_/\_\
";

static DEVICETREE: Once<Devicetree> = Once::new();

fn call_with_panic_report<F, T, E>(panic_message: &str, f: F) -> T
where
    F: FnOnce() -> Result<T, E>,
    E: error::Error,
{
    f().unwrap_or_else(|e| {
        let panic_message = WithFg::new(Color::Red, panic_message);
        let report = Report::new(e);
        panic!("{panic_message}\n\n{report}");
    })
}

#[derive(Debug, Snafu)]
#[snafu(module)]
enum PrimaryCpuEntryError {
    #[snafu(display("failed to initialize heap and devicetree"))]
    #[snafu(provide(ref, priority, Location => location))]
    InitHeapAndDevicetree {
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: InitHeapAndDevicetreeError,
    },
    #[snafu(display("failed to initialize CPU table"))]
    #[snafu(provide(ref, priority, Location => location))]
    InitCpu {
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: Box<cpu::CpuInitError>,
    },
    #[snafu(display("failed to initialize kernel space"))]
    #[snafu(provide(ref, priority, Location => location))]
    InitKernelSpace {
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: memory::kernel_space::KernelSpaceInitError,
    },
    #[snafu(display("failed to update kernel page table"))]
    #[snafu(provide(ref, priority, Location => location))]
    UpdateKernelPageTable {
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: memory::layout::UpdateKernelPageTableError,
    },
    #[snafu(display("failed to allocate kernel stack"))]
    #[snafu(provide(ref, priority, Location => location))]
    AllocateKernelStack {
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: memory::kernel_space::AllocateKernelStackError,
    },
}

fn primary_cpu_entry(cpuid: Cpuid, dtb_pa: usize) -> *mut u8 {
    #[expect(clippy::wildcard_imports)]
    use self::primary_cpu_entry_error::*;

    memory::allocator::init();

    println!();
    println!();
    println!("Onix v{ONIX_VERSION}");
    println!("{ONIX_LOGO}");

    call_with_panic_report(
        "error during initialization of primary CPU",
        || -> Result<_, PrimaryCpuEntryError> {
            let memory_layout =
                init_heap_and_devicetree(dtb_pa).context(InitHeapAndDevicetreeSnafu)?;
            let dtree = DEVICETREE.get().unwrap();
            cpu::init(dtree).context(InitCpuSnafu)?;
            cpu_local::init();
            cpu_local::apply(cpuid);
            cpu::set_current_cpuid(cpuid);
            interrupt::init(cpuid);
            memory::kernel_space::init().context(InitKernelSpaceSnafu)?;
            memory::layout::update_kernel_page_table(&memory_layout)
                .context(UpdateKernelPageTableSnafu)?;
            memory::kernel_space::apply();

            let stack =
                memory::kernel_space::allocate_kernel_stack().context(AllocateKernelStackSnafu)?;
            let stack_top = stack.top();
            core::mem::forget(stack);

            Ok(stack_top as *mut u8)
        },
    )
}

#[derive(Debug, Snafu)]
#[snafu(module)]
enum SecondaryCpuEntryError {
    #[snafu(display("failed to allocate kernel stack"))]
    #[snafu(provide(ref, priority, Location => location))]
    AllocateKernelStack {
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: memory::kernel_space::AllocateKernelStackError,
    },
}

fn secondary_cpu_entry(cpuid: Cpuid) -> *mut u8 {
    #[expect(clippy::wildcard_imports)]
    use self::secondary_cpu_entry_error::*;

    call_with_panic_report(
        "error during initialization of secondary CPU",
        || -> Result<_, SecondaryCpuEntryError> {
            cpu_local::apply(cpuid);
            cpu::set_current_cpuid(cpuid);
            memory::kernel_space::apply();

            let stack =
                memory::kernel_space::allocate_kernel_stack().context(AllocateKernelStackSnafu)?;
            let stack_top = stack.top();
            core::mem::forget(stack);
            Ok(stack_top as *mut u8)
        },
    )
}

#[derive(Debug, Snafu)]
#[snafu(module)]
enum MainError {
    #[snafu(display("failed to initialize PLIC device drivers"))]
    #[snafu(provide(ref, priority, Location => location))]
    InitPlicDrivers {
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: Box<drivers::irq::plic::PlicInitError>,
    },
    #[snafu(display("failed to initialize serial device drivers"))]
    #[snafu(provide(ref, priority, Location => location))]
    InitSerialDrivers {
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: Box<drivers::serial::SerialInitError>,
    },
}

fn main(is_primary: bool) -> ! {
    static INIT_COMPLETED: AtomicBool = AtomicBool::new(false);

    call_with_panic_report(
        "error occurred within kernel main function",
        || -> Result<_, MainError> {
            if is_primary {
                unsafe {
                    start_secondary_cpus();
                }

                let dtree = DEVICETREE.get().unwrap();
                drivers::irq::plic::init(dtree).context(InitPlicDriversSnafu)?;
                drivers::serial::init(dtree).context(InitSerialDriversSnafu)?;

                INIT_COMPLETED.store(true, Ordering::Release);
            } else {
                while !INIT_COMPLETED.load(Ordering::Acquire) {
                    hint::spin_loop();
                }
            }

            drivers::serial::apply();
            interrupt::trap::apply();
            interrupt::timer::start();

            info!("CPU initialized");

            if is_primary {
                spawn_test_tasks();
            }

            task::scheduler::start()
        },
    )
}

#[derive(Debug, Snafu)]
#[snafu(module)]
enum InitHeapAndDevicetreeError {
    #[snafu(display("failed to create devicetree at physical address {dtb_pa:#x}"))]
    #[snafu(provide(ref, priority, Location => location))]
    CreateDevicetree {
        dtb_pa: usize,
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: devicetree::flattened::CreateError,
    },
    #[snafu(display(
        "failed to compute memory layout from devicetree at physical address {dtb_pa:#x}"
    ))]
    #[snafu(provide(ref, priority, Location => location))]
    ComputeMemoryLayout {
        dtb_pa: usize,
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: memory::layout::CreateMemoryLayoutError,
    },
    #[snafu(display("failed to parse devicetree at physical address {dtb_pa:#x}"))]
    #[snafu(provide(ref, priority, Location => location))]
    ParseDevicetree {
        dtb_pa: usize,
        #[snafu(implicit)]
        location: Location,
        #[snafu(source)]
        source: devicetree::flattened::node::ParseStructError,
    },
}

fn init_heap_and_devicetree(dtb_pa: usize) -> Result<MemoryLayout, InitHeapAndDevicetreeError> {
    #[expect(clippy::wildcard_imports)]
    use self::init_heap_and_devicetree_error::*;

    let dtb = unsafe { devicetree::flattened::Devicetree::from_addr(dtb_pa) }
        .context(CreateDevicetreeSnafu { dtb_pa })?;
    let memory_layout = MemoryLayout::new(&dtb).context(ComputeMemoryLayoutSnafu { dtb_pa })?;

    // initialize heap
    unsafe {
        memory::allocator::add_heap_ranges(memory_layout.initial_heap_ranges());
    }

    // parse devicetree blob
    DEVICETREE
        .try_call_once(|| dtb.parse())
        .context(ParseDevicetreeSnafu { dtb_pa })?;

    // reuse devicetree blob range as heap
    unsafe {
        memory::allocator::add_heap_ranges([memory_layout.dtb_range()]);
    }

    Ok(memory_layout)
}

unsafe fn start_secondary_cpus() {
    for cpu in cpu::get_all() {
        if cpu.is_current() {
            continue;
        }
        unsafe {
            boot::start_secondary_cpu(cpu.id());
        }
    }

    // reuse boot stack as heap
    unsafe {
        memory::allocator::add_heap_ranges([memory::layout::kernel_boot_stack_range()]);
    }
}

struct TaskState {
    queue: SpinMutex<VecDeque<(TaskId, u64, Instant)>>,
    message_sent: SpinMutexCondVar,
    message_received: SpinMutexCondVar,
}

fn spawn_test_tasks() {
    let state = Arc::new(TaskState {
        queue: SpinMutex::new(VecDeque::new()),
        message_sent: SpinMutexCondVar::new(),
        message_received: SpinMutexCondVar::new(),
    });

    task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(rx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
    task::spawn(tx_task, Arc::into_raw(Arc::clone(&state)).cast_mut().cast()).unwrap();
}

extern "C" fn tx_task(arg: *mut c_void) -> ! {
    let task_id = scheduler::current_task().id();

    let state: Arc<TaskState> = unsafe { Arc::from_raw(arg.cast()) };

    let mut i = 0;
    let mut queue = state.queue.lock();
    loop {
        if queue.len() < 4 {
            queue.push_back((task_id, i, Instant::now()));
            state.message_sent.notify_one();
            queue.unlock();
            i += 1;
            timer::sleep(Duration::from_millis(50));
            queue = state.queue.lock();
        } else {
            queue = state.message_received.wait(queue);
        }
    }
}

extern "C" fn rx_task(arg: *mut c_void) -> ! {
    let state: Arc<TaskState> = unsafe { Arc::from_raw(arg.cast()) };
    let task = scheduler::current_task();

    let mut handled = 0;
    let mut total_dur = Duration::ZERO;
    let mut min_dur = Duration::MAX;
    let mut max_dur = Duration::ZERO;
    let mut queue = state.queue.lock();
    loop {
        if let Some((_task_id, i, time)) = queue.pop_front() {
            state.message_received.notify_all();
            queue.unlock();
            let dur = time.elapsed();
            min_dur = min_dur.min(dur);
            max_dur = max_dur.max(dur);
            total_dur += dur;
            handled += 1;
            let avg_dur = total_dur / handled;
            if (i + 1) % 50 == 0 {
                info!(
                    "received, handled={handled}, avg_dur={avg_dur:?}, min_dur={min_dur:?}, \
                     max_dur={max_dur:?}"
                );
            }
            let mut shared = task.shared.lock();
            scheduler::yield_execution(&mut shared);
            shared.unlock();
            queue = state.queue.lock();
        } else {
            queue = state.message_sent.wait(queue);
        }
    }
}
